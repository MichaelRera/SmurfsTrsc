?dplyr::between()
lapply(time2, function(i) ifelse(between(i, example$t_birth[1], example$t_death[2]), TRUE, FALSE))
library(tidyverse)
lapply(time2, function(i) ifelse(between(i, example$t_birth[1], example$t_death[2]), TRUE, FALSE))
lapply(time2, function(i) ifelse(between(i, example$t_birth, example$t_death), TRUE, FALSE))
?slice
?mapply
comparison = function(t_birth_vector, t_death_vector, time_point) {
for(1:length(t_birth_vector) {
ifelse(between(i, example$t_birth, example$t_death), TRUE, FALSE)
})
}
for(1:length(t_birth_vector) {
ifelse(between(i, example$t_birth, example$t_death), TRUE, FALSE)
}
}
lapply(time2, function(i) ifelse(between(i, example$t_birth, example$t_death), TRUE, FALSE))
comparison = function(t_birth_vector, t_death_vector, time_point) {
comparison = function(t_birth_vector, t_death_vector, time_point){
ccc
cccccccccccccccccc
frfff
comparison = function(t_birth_vector, t_death_vector, time_point){
cccc
fdekfezjkfhnjzkef
.
::::
for(1:length(t_birth_vector) {
ifelse(between(i, example$t_birth, example$t_death), TRUE, FALSE)
}
library(tidyverse)
for(1:length(t_birth_vector) {
ifelse(between(i, example$t_birth, example$t_death), TRUE, FALSE)
}
example
for(1:length(example$t_birth) {
ifelse(between(i, example$t_birth, example$t_death), TRUE, FALSE)
}
for(1:length(example$t_birth) { ifelse(between(i, example$t_birth, example$t_death), TRUE, FALSE) }
1:length(example$t_birth
)
1:max(example$t_birth
)
## New implementation that includes t0
S <- function(t, a, k, t0, P0) {
f <- function(s) exp(-a / 2 * pmax(s - t0, 0) ^ 2) * exp(k * s) * pmax(s - t0, 0)
integral <- sapply(t, function(upper) integrate(f, lower = t0, upper = upper)$value)
a * P0 * exp(-k * t) * integral
}
N <- function(t, a, k, t0, P0) {
P0 * exp(-a / 2 * pmax(0, t - t0) ^ 2)
}
P <- function(t, a, k, t0, P0) N(t, a, k, t0, P0) + S(t, a, k, t0, P0)
k = 1
a = 1
t = seq(0, 7, 0.001)
P0 = 10
t0 <- 2
plot(t, N(t, a, k, t0, P0), type = 'l', col = "darkblue")
lines(t, S(t, a, k, t0, P0), col = "darkgreen")
lines(t, P(t, a, k, t0, P0), col = "darkred")
# Estimate the model parameters on simulated data
set.seed(0)
data <- rnorm(100, 0.6, 0.1)
data <- sort(data)
plot(data, 1 - ecdf(data)(data), type = 'S') # Empirical survival curve of the data
# Define the cost function to minimize in order to estimate "a" and "k".
cost <- function(par, data) {
a <- par[1]; k <- par[2]; t0 = par[3]
surv_data <- 1 - ecdf(data)(data) # compute the empirical survival function at the data points
sum((surv_data - P(data, a, k, t0, P0 = 1)) ^ 2) # compute the sum of squared differences
}
# Perform estimation
est_par <- optim(c(1, 1, 0), fn = cost, data = data)$par
# Plot empirical survival function
t <- seq(0, max(data) * 1.5, 0.01)
est_par
plot(t, 1 - ecdf(data)(t), type = "S")
lines(t, P(t, est_par[1], est_par[2], est_par[3], 1), col = "darkred")
lines(t, N(t, est_par[1], est_par[2], est_par[3], 1), col = "darkblue")
lines(t, S(t, est_par[1], est_par[2], est_par[3], 1), col = "darkgreen")
?shapiro.test
shapiro.test(rnorm(100))
shapiro.test(rnorm(10000))
shapiro.test(rnorm(1000))
data = data.frame(A = c("yes", "no", "yes", "no"), B = c(1,2,3,4), C = c(5,6,7,8))
data
data %>% mutate(mean = mean(B,C), sd = sd(B,C))
library(tidyverse)
data1 = data %>% mutate(mean = mean(B,C), sd = sd(B,C))
data %>% mutate(mean = mean(B,C))
data %>% mutate(colmean = mean(B,C))
?mean
mutate(colmean = mean(x =c(B,C))
ddfddd
data %>% mutate(colmean = mean(x =c(B,C))
)
data %>% mutate(extra = A+B)
mutate(extra = .$A + .$B)
data %>% mutate(new_column = ifelse(A == "yes", mean(.$B,.$C), sd(.$B,.$C)))
data %>% mutate(new_column = ifelse(A == "yes", mean(c(.$B,.$C))))
data %>% mutate(new_column = ifelse(A == "yes", mean(c(.$B,.$C)), "no"))
data %>% mutate(extra = .$A + .$B)
library(data.table)
data %>% as.data.table() %>% .[, newcol := A+B]
data
data %>% as.data.table()
data %>% as.data.table() %>% .[, newcol := sum(A,B)]
?sum
myf <- function(tens, ones) { 10 * tens + ones }
x <- data.frame(hundreds = 7:9, tens = 1:3, ones = 4:6)
mutate(x, value = myf(tens, ones))
mutate(x, value = ifelse(hundreds == 7, myf(tens,ones), "no_match"))
load("/home/f-zane/Google Drive/RNAseq_Analysis/ENSEMBL_annotation/Deseq/DESeq_design/res_daysandcondition.RData")
res
res[grep("FBgn0001258", rownames(res), ignore.case = TRUE),]
res[grep("Hex", res$symbol, ignore.case = TRUE),]
res[grep("tfam", rownames(res), ignore.case = TRUE),]
res[grep("tfam", res$symbol, ignore.case = TRUE),]
?wilcox.test
summary(lm(log1p(expression) ~ time + smurfness + time * smurfness, data = gathered_down))
library(pathview)
packageVersion("pathview")
?optim
#set the working directory
#setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
setwd("/home/f-zane/Google Drive/PAPER_SMURF_TRANSCRIPTOME/tidied_code/")
#load here libraries that are needed all along
library(org.Dm.eg.db); library(tidyverse); library(DESeq2)
library(data.table)
#assign the dataset to an object
raw_data <- fread("raw_data_matrix.tabular") %>%
column_to_rownames(var="Geneid") %>% select(contains("s")) #select only the non-smurf ones
#remove the genes that are never detected
raw_data = raw_data[which(rowSums(raw_data) > 0),]
library(ggrepel)
#creation of the colData object with data annotation, needed for the DESeq2 framework
colData = data.frame(samples = colnames(raw_data)) %>%
mutate(days = ifelse(str_starts(samples, "20"), "20", ifelse(str_starts(samples, "40"), "40", "30"))) %>% #chronological age
#mutate(condition = ifelse(str_detect(samples, "s"), "S", "NS")) %>% #condition (smurfs or non-smurfs)
mutate(time = ifelse(str_detect(samples, "M"), "mixed", ifelse(str_detect(samples, "1d"), "24h", "5h"))) %>% #moment of sampling after the smurf transition
column_to_rownames(var="samples")  #respect the format required by Deseq2 by putting samples as rownames
colData$days = as.factor(colData$days)
#Create dds object, which will also be used in further analysis (differential gene expression)
#this step also implies data normalization
#design the matrix to keep into consideration the different biological variables
dds1 <- DESeqDataSetFromMatrix(countData = raw_data, colData = colData, design = ~ days)
#apply a transformation to stabilize the variance prior to perform PCA on gene expression data
vst <- vst(dds1)
#apply a transformation to stabilize the variance prior to perform PCA on gene expression data
vst <- vst(dds1)
#run PCA, on the top 5000 genes in terms of variance. The ntop parameter can change depending on the needs of the analysis, default is 500.
pca = plotPCA(vst, intgroup = c( "days"), ntop =5000, returnData = TRUE)
#run PCA, on the top 5000 genes in terms of variance. The ntop parameter can change depending on the needs of the analysis, default is 500.
pca = plotPCA(vst, intgroup = c( "days"), ntop =5000, returnData = TRUE)
percentVar <- round(100 * attr(pca, "percentVar"))
#visualize coordinates
pca
#plot the PCA manually with ggplot2 for better customization
pca_plot = ggplot(pca, aes(PC1, PC2, color= as.factor(days))) +
geom_point(size=3.8, alpha = 0.9) +
xlab(paste0("PC1: ",percentVar[1],"% variance")) +
ylab(paste0("PC2: ",percentVar[2],"% variance")) +
geom_hline(yintercept = 0, linetype = "dotted", alpha = 0.5) +
geom_vline(xintercept = 0, linetype = "dotted", alpha = 0.5) +
geom_text_repel(aes(label = rownames(pca)), size = 3.5) +
coord_fixed() +
scale_color_manual(values = c("darkgoldenrod1", "chocolate1", "brown"), name = "Age", labels = c("20 days", "30 days", "40 days")) +
ggtitle("PCA RNAseq samples") +
scale_shape_discrete(name = "Age", labels = c("20 days", "30 days", "40 days")) +
theme_light() +
theme(legend.position = "top", legend.direction = "horizontal", plot.title = element_text(hjust = 0.5))
#plot the PCA manually with ggplot2 for better customization
pca_plot = ggplot(pca, aes(PC1, PC2, color= as.factor(days))) +
geom_point(size=3.8, alpha = 0.9) +
xlab(paste0("PC1: ",percentVar[1],"% variance")) +
ylab(paste0("PC2: ",percentVar[2],"% variance")) +
geom_hline(yintercept = 0, linetype = "dotted", alpha = 0.5) +
geom_vline(xintercept = 0, linetype = "dotted", alpha = 0.5) +
geom_text_repel(aes(label = rownames(pca)), size = 3.5) +
coord_fixed() +
scale_color_manual(values = c("darkgoldenrod1", "chocolate1", "brown"), name = "Age", labels = c("20 days", "30 days", "40 days")) +
ggtitle("PCA RNAseq samples") +
scale_shape_discrete(name = "Age", labels = c("20 days", "30 days", "40 days")) +
theme_light() +
theme(legend.position = "top", legend.direction = "horizontal", plot.title = element_text(hjust = 0.5))
pca_plot
#use the same dds object generated before for the PCA, and perform the second step
dds2 = DESeq(dds1)
#compute the results object and set the alpha for the FDR at the threshold that I want to choose after
res_s = results(dds2, contrast = c("days", "40", "20"), alpha = 0.05)
sign_s = res_s %>% as.data.frame() %>% filter(padj <= 0.05)
#visualization through Volcano plot
#shirk the log2fold change for visualization
lfc_apeglm =lfcShrink(dds2, res = res_s, coef = "days_40_vs_20" , type="apeglm")
#add information that needs to be displayed in the plot
apeglm_for_plot = lfc_apeglm %>% as.data.frame() %>%
rownames_to_column(var = "flybase") %>% dplyr::select(c("flybase", "log2FoldChange", "padj")) %>% na.omit() %>%
mutate(significance = ifelse(padj <= 0.05, "signif", "non_signif")) %>%
mutate(symbol = mapIds(org.Dm.eg.db,
keys= .$flybase,
column="SYMBOL",
keytype="ENSEMBL",
multiVals="first")) %>%
mutate(annot = ifelse(log2FoldChange < -2, symbol, ifelse(log2FoldChange > 2, symbol, ""))) %>%
mutate(annot = ifelse(is.na(annot), flybase, annot))
#plot, label for the genes that have a log2FC > |2|
ggplot(apeglm_for_plot, aes(log2FoldChange, -log10(padj)))+ geom_point(aes(col = significance), alpha = 0.5) + theme_light() +
scale_color_manual(name = "FDR 5%", labels = c("Non significant", "Significant"), values = c("lightgrey", "red")) +
theme(legend.position = "bottom", legend.direction = "horizontal") + geom_text_repel(aes(label = annot), size = 4.3) +
ylab("-log10(FDR)") + xlab("log2FoldChange Smurfs/non-Smurfs")
##use the same dataset used for the PCA, vst (stabilized variance) rather than simply the normalized counts
#filter for the DEGs
vst_df = vst %>% assay %>% as.data.frame()
vst_diff = vst_df[rownames(vst_df) %in% rownames(sign_s),]
require(heatmap3)
##prepare annotation for the heatmap plot
vst_mat_005 = vst_diff %>% as.matrix
annot = data.frame(samples = colnames(vst_mat_005)) %>%
mutate(condition = ifelse(grepl("n", .$samples), "NS", "S")) %>%
mutate(age = ifelse(grepl("20", .$samples), "20",
ifelse(grepl("40", .$samples), "40",
ifelse(grepl("30", .$samples), "30", "32")))) %>%
#mutate(smurfness = ifelse(condition == "NS", "lightgrey", "blue")) %>%
mutate(days = ifelse(age == "20", "darkgoldenrod1", ifelse(age == "40", "brown", "chocolate1")))
annot_hp = annot %>% select(c("days")) %>% as.matrix
rownames(annot_hp) = annot$samples
#plot with heatmap3, default for computing the matrix is correlation
heatmap3(vst_mat_005 , scale = "row", ColSideColors = annot_hp,
labRow   = FALSE, labCol = FALSE, showRowDendro = F, legendfun = function()
showLegend(legend = c("20 days", "30 days", "40 days"),
fill = c("darkgoldenrod1", "chocolate1", "brown"), lwd = 0,
col=colorRampPalette(c("green","black","red"))(1024)))
require(clusterProfiler)
##list of genes to use: as reccomended in the DESeq2 guidelines, use of the shrinked log2FC for ranking
lfc_apeglm = lfc_apeglm %>% as.data.frame() %>% rownames_to_column(var = "gene_flybase") %>%
mutate(entrez = mapIds(org.Dm.eg.db,
keys = .$gene_flybase,
column = "ENTREZID", #add the entrez nomenclature that is required (as the downloaded GO are annotated this way)
keytype = "ENSEMBL",
multiVals = "first"))
#filter only the genes we are interested in
res_apeg <- lfc_apeglm  %>% filter(padj <= 0.05) %>%  dplyr::select(c("gene_flybase", "log2FoldChange", "entrez"))
#creating the gene list and ranking it
#getting the sorted gene list
gene_list <- as.numeric(res_apeg$log2FoldChange)
names(gene_list) <- as.character(res_apeg$gene_flybase)
gene_list = gene_list[!is.na(names(gene_list))] %>% .[!duplicated(names(.))] %>% sort(., decreasing = TRUE)
#run the analysis
n = 1 #number of times repeating
P = 80 #percentage for selection
pval = 0.05 #threshold to apply
gse_go = vector("list", n)
organism = "org.Dm.eg.db"
library(organism, character.only = TRUE) #library is already loaded
set.seed(123)
for (i in 1:length(gse_go)) {
gse_go[[i]] <- gseGO(geneList= gene_list,
ont ="BP",
keyType = "ENSEMBL",
nPerm = 15000,
minGSSize = 10,
maxGSSize = 600,
pvalueCutoff = 0.05, #change the significance level
verbose = TRUE,
OrgDb = organism,
pAdjustMethod = "fdr") # %>% as.data.frame()
}
#perform the filtering with the 80% threshold
#transform the objects in the list to dataframe
df_gse = lapply(gse_go, function(x) as.data.frame(x))
#extract the categories of interest
categories = lapply(df_gse, function(x) x$Description)
#IF I WANT TO KEEP ONLY THE ONES THAT ARE OCCURING EVERYTIME
#Reduce(intersect, a )
#IF I WANT TO FILTER FOR P% PRESENCE OF THE CATEGORY
filtering_vector = tibble(category = unlist(categories)) %>% #unlist the list and making it a tibble
group_by(category) %>%
summarise(count = n()) %>% #group by category and generate a new column counting how many times a category occurs
mutate(percentage_presence = count/n*100) %>% #adding a column with the persentage
#arrange(desc(count)) %>% #adding this only if we want to visualize
filter(percentage_presence >= P)
filtering_vector
sign_s %>% dim
#run the analysis
n = 50 #number of times repeating
P = 80 #percentage for selection
pval = 0.05 #threshold to apply
gse_go = vector("list", n)
organism = "org.Dm.eg.db"
library(organism, character.only = TRUE) #library is already loaded
set.seed(123)
for (i in 1:length(gse_go)) {
gse_go[[i]] <- gseGO(geneList= gene_list,
ont ="BP",
keyType = "ENSEMBL",
nPerm = 15000,
minGSSize = 10,
maxGSSize = 600,
pvalueCutoff = 0.05, #change the significance level
verbose = TRUE,
OrgDb = organism,
pAdjustMethod = "fdr") # %>% as.data.frame()
}
warnings()
#perform the filtering with the 80% threshold
#transform the objects in the list to dataframe
df_gse = lapply(gse_go, function(x) as.data.frame(x))
#extract the categories of interest
categories = lapply(df_gse, function(x) x$Description)
#IF I WANT TO KEEP ONLY THE ONES THAT ARE OCCURING EVERYTIME
#Reduce(intersect, a )
#IF I WANT TO FILTER FOR P% PRESENCE OF THE CATEGORY
filtering_vector = tibble(category = unlist(categories)) %>% #unlist the list and making it a tibble
group_by(category) %>%
summarise(count = n()) %>% #group by category and generate a new column counting how many times a category occurs
mutate(percentage_presence = count/n*100) %>% #adding a column with the persentage
#arrange(desc(count)) %>% #adding this only if we want to visualize
filter(percentage_presence >= P)
filtering_vector %>% dim
filtering_vector
##find a gse_go that has all of them
df_gse[[1]]$Description %in% filtering_vector$category %>% sum
##FOR THE PLOT
plot_gse = gse_go[[1]]
emapplot(plot_gse, showCategory = filtering_vector$category, color = "NES",
layout = "fr", cex_label_category = 0.1) + scale_color_gradient(low = "blue" , high = "red" ) #selecting the categories we want with "showCategory"
save(gse_go, "gse_go_smurfs_analysis.RData")
dev.off()
save(gse_go, file = "gse_go_smurfs_analysis.RData")
sign_s %>% dim
sign_s %>% filter(log2FoldChange > 0)
sign_s %>% filter(log2FoldChange > 0) %>% dim
plot_gse %>% head
plot_gse %>% class
##find a gse_go that has all of them
df_gse[[1]]$Description %in% filtering_vector$category %>% sum
filtering_vector %>% dim
df_to_plot = df_gse[[1]]$Description %in% filtering_vector$category
df_to_plot
df_to_plot = df_gse[[1]][df_gse[[1]]$Description %in% filtering_vector$category,]
df_to_plot
df_to_plot %>% dim
df_to_plot$NES > 0 %>% sum
df_to_plot$NES < 0 %>% sum
(df_to_plot$NES) < 0 %>% sum
(df_to_plot$NES < 0) %>% sum
(df_to_plot$NES > 0) %>% sum
require(ggplot2)
pca <- prcomp(iris[,-5])
dataset = data.frame(species = iris[,"Species"], pca = pca$x)
mx <- mean(dataset$pca.PC1)
my <- mean(dataset$pca.PC2)
ggplot(dataset) +
geom_point(aes(pca.PC1, pca.PC2, colour = species, shape = species),
size = 4) +
geom_point(aes(mx,my), size = 7)
library(ggbiplot)
data(wine)
wine.pca <- prcomp(wine, center = TRUE, scale. = TRUE)
df.wine.x <- as.data.frame(wine.pca$x)
df.wine.x$groups <- wine.class
pca.centroids <- aggregate(df.wine.x[,1:13], list(Type = df.wine.x$groups), mean)
pca.centroids
dist(rbind(pca.centroids[pca.centroids$Type == "barolo",2:3],pca.centroids[pca.centroids$Type == "grignolino",2:3]), method = "euclidean")
rm(list = ls())
#sourcing a few functions to get the coldata attributes in deseq2
source("/home/f-zane/Google Drive/RNAseq_Analysis/ENSEMBL_annotation/Deseq/coldata_functions.R")
##data uploading
raw_data <- fread("/home/f-zane/Google Drive/RNAseq_Analysis/ENSEMBL_annotation/Deseq/Galaxy170-[FeatureCounts_Table_-_Short_Headers].tabular") %>%
column_to_rownames(var="Geneid")
library(data.table)
library(tidyverse)
library(DESeq2)
library(edgeR)
library(ggfortify)
#sourcing a few functions to get the coldata attributes in deseq2
source("/home/f-zane/Google Drive/RNAseq_Analysis/ENSEMBL_annotation/Deseq/coldata_functions.R")
##data uploading
raw_data <- fread("/home/f-zane/Google Drive/RNAseq_Analysis/ENSEMBL_annotation/Deseq/Galaxy170-[FeatureCounts_Table_-_Short_Headers].tabular") %>%
column_to_rownames(var="Geneid")
#removing genes with 0 counts (most of all are )
raw_data = raw_data[which(rowSums(raw_data) > 0),] #to avoid
##deriving the coldata attributes (which sample is S, 20days etc..)
days <-  sapply(colnames(raw_data), getting_days)
time <-  sapply(colnames(raw_data), getting_time)
condition <-  sapply(colnames(raw_data), getting_condition)
#creating the colData object
colData <- data.frame(samples = colnames(raw_data), condition = condition, time = time, days = days, row.names = NULL)
colData$days = as.factor(colData$days)
#creating the dds object
dds <- DESeqDataSetFromMatrix(countData = raw_data, colData = colData, design = ~ condition)
##with VST transformation (variance stabilizing trasformation)
##getting variance independent from the mean and get homoscedasticity
##STANDARDIZATION PROCESS REQUIRED FOR THE PCA
vst <- vst(dds)
pca_1000 = plotPCA(vst, intgroup = c("condition", "days"), ntop =1000, returnData = TRUE)
#pca_2000 = plotPCA(vst, intgroup = c("condition", "days"), ntop =2000, returnData = TRUE)
#pca_all = plotPCA(vst, intgroup = c("condition", "days"), ntop = nrow(raw_data), returnData = TRUE)
percentVar <- round(100 * attr(pca_1000, "percentVar"))
#percentVar <- round(100 * attr(pca_all, "percentVar"))
##same with rlog transformation
# The idea is to shrink sample-to-sample differences when
# there is little information (low counts) and to preserve
# these differences when there is information (high counts). (M.Love)
rlog <- rlog(dds)
pca_1000_log = plotPCA(rlog, intgroup = c("condition", "days"), ntop =1000, returnData = TRUE)
#pca_7000_log = plotPCA(rlog, intgroup = c("condition", "days"), ntop =2000, returnData = TRUE)
#pca_all_log = plotPCA(rlog, intgroup = c("condition", "days"), ntop = nrow(raw_data), returnData = TRUE)
percentVar_log <- round(100 * attr(pca_1000_log, "percentVar"))
#percentVar <- round(100 * attr(pca_all_log, "percentVar"))
#plot the pca without
#color=condition plot
p = ggplot(pca_1000, aes(PC1, PC2, color=condition, shape=days)) +
geom_point(size=2) +
xlab(paste0("PC1: ",percentVar[1],"% variance")) +
ylab(paste0("PC2: ",percentVar[2],"% variance")) +
coord_fixed() +
ggtitle("PCA RNAseq samples vst transform ntop = 1000 ")
p_log = ggplot(pca_1000_log, aes(PC1, PC2, color=condition, shape=days)) +
geom_point(size=2) +
xlab(paste0("PC1: ",percentVar_log[1],"% variance")) +
ylab(paste0("PC2: ",percentVar_log[2],"% variance")) +
coord_fixed() +
ggtitle("PCA RNAseq samples rlog transform ntop = 1000")
p + theme(
plot.title = element_text(color="black", size=12, face="bold", hjust = 0.5, family = ""))
#ggsave("pcavst.pdf")
p_log + theme(
plot.title = element_text(color="black", size=12, face="bold", hjust = 0.5, family = ""))
#ggsave("pcarlog.pdf")
## For the presentation
# p +
#   ggtitle("PCA RNAseq samples VST") +
#   scale_color_discrete(name = "Condition", labels = c("Non Smurf", "Smurf")) +
#   scale_shape_discrete(name = "Number of days") +
#   theme(
#     plot.title = element_text(color="black", size=12, face="bold", hjust = 0.5, family = ""),
#     plot.margin=grid::unit(c(0,0,0,0), "mm"))
#from the raw data computing the scaling factor
tmm_factor = calcNormFactors(raw_data, method = "TMM") #this function gives back the scaling factor
#now to get the TMM
#count / (library size * normalization factor)
#library size == total number of reads for the given sample
#library size*normalization factor = effective library size
#get (library size * normalization factor)
library_size <- as.vector(colSums(raw_data))
multiply = function(x,y) {x*y}
effective_library_size = mapply(multiply, tmm_factor, library_size)
# tmm
tmm_data = matrix(NA, nrow = nrow(raw_data), ncol = length(effective_library_size)) %>%
as.data.frame()
for (i in 1:ncol(raw_data)){
tmm_data[,i] = raw_data[,i]/effective_library_size[i]
}
colnames(tmm_data) = colnames(raw_data)
rownames(tmm_data) = rownames(raw_data)
##then get CPM
cpm_data = cpm(raw_data, log= T)
transpose_cpm = t(as.matrix(cpm_data)) %>%
as.data.table()
##select the top genes
rv <- rowVars(cpm_data)
# select the ntop genes by variance
ntop= 1000
select <- order(rv, decreasing=TRUE)[seq_len(ntop)]
# perform a PCA on the data in assay(x) for the selected genes
pca <- prcomp(t(cpm_data[select,]))
##plot the pca*
days <-  sapply(colnames(raw_data), getting_days)
time <-  sapply(colnames(raw_data), getting_time)
condition <-  sapply(colnames(raw_data), getting_condition)
transpose_cpm_annot = mutate(transpose_cpm, condition = condition, days = days)
rownames(transpose_cpm_annot) = colnames(raw_data)
# pca = prcomp(transpose_cpm)
p = autoplot(pca,  data = transpose_cpm_annot, colour = "condition", label = TRUE,
label.size =3, main = "PCA log2cpm ntop = 1000")
p + theme(
plot.title = element_text(color="black", size=12, face="bold", hjust = 0.5, family = ""))
data_tsne = t(cpm_data) %>%
#normalize_input() %>%  #already normalized
as.data.frame() %>%
mutate(condition = condition, days = days)
rownames(data_tsne) <- colnames(cpm_data)
set.seed(42)
require(FactoMineR)
#getting the PCA extracting different numbers of components
res.pca_2<- PCA(t(cpm_data[select,]), ncp = 2)
res.pca_10<- PCA(t(cpm_data[select,]), ncp = 10)
res.pca_30<- PCA(t(cpm_data[select,]), ncp = 30)
res.pca_30
?PCA
res.hcpc_2 = HCPC(res.pca_2, order = TRUE)
library(tidyverse)
library(tidyverse)
install.packages(tidyverse)
install.packages("tidyverse")
installed.packages()
#print the R environment
Rversion()
#print the R environment
R.version()
#print the R environment
R.Version()
#print the R environment
R_version =R.Version()
#print the R environment
R_version = R.Version()
####Infer a linear model on gene expression using smurfness, age and the interaction as variable
####this analysis is mentioned in the main text at the end of the section: "Old Smurfs carry additional related changes"
#set the working directory if needed
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #setting current working directory
