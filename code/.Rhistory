#mutate(condition = ifelse(str_detect(samples, "s"), "S", "NS")) %>% #condition (smurfs or non-smurfs)
mutate(time = ifelse(str_detect(samples, "M"), "mixed", ifelse(str_detect(samples, "1d"), "24h", "5h"))) %>% #moment of sampling after the smurf transition
column_to_rownames(var="samples")  #respect the format required by Deseq2 by putting samples as rownames
colData$days = as.factor(colData$days)
#Create dds object, which will also be used in further analysis (differential gene expression)
#this step also implies data normalization
#design the matrix to keep into consideration the different biological variables
dds1 <- DESeqDataSetFromMatrix(countData = raw_data, colData = colData, design = ~ days)
#apply a transformation to stabilize the variance prior to perform PCA on gene expression data
vst <- vst(dds1)
#apply a transformation to stabilize the variance prior to perform PCA on gene expression data
vst <- vst(dds1)
#run PCA, on the top 5000 genes in terms of variance. The ntop parameter can change depending on the needs of the analysis, default is 500.
pca = plotPCA(vst, intgroup = c( "days"), ntop =5000, returnData = TRUE)
#run PCA, on the top 5000 genes in terms of variance. The ntop parameter can change depending on the needs of the analysis, default is 500.
pca = plotPCA(vst, intgroup = c( "days"), ntop =5000, returnData = TRUE)
percentVar <- round(100 * attr(pca, "percentVar"))
#visualize coordinates
pca
#plot the PCA manually with ggplot2 for better customization
pca_plot = ggplot(pca, aes(PC1, PC2, color= as.factor(days))) +
geom_point(size=3.8, alpha = 0.9) +
xlab(paste0("PC1: ",percentVar[1],"% variance")) +
ylab(paste0("PC2: ",percentVar[2],"% variance")) +
geom_hline(yintercept = 0, linetype = "dotted", alpha = 0.5) +
geom_vline(xintercept = 0, linetype = "dotted", alpha = 0.5) +
geom_text_repel(aes(label = rownames(pca)), size = 3.5) +
coord_fixed() +
scale_color_manual(values = c("darkgoldenrod1", "chocolate1", "brown"), name = "Age", labels = c("20 days", "30 days", "40 days")) +
ggtitle("PCA RNAseq samples") +
scale_shape_discrete(name = "Age", labels = c("20 days", "30 days", "40 days")) +
theme_light() +
theme(legend.position = "top", legend.direction = "horizontal", plot.title = element_text(hjust = 0.5))
#plot the PCA manually with ggplot2 for better customization
pca_plot = ggplot(pca, aes(PC1, PC2, color= as.factor(days))) +
geom_point(size=3.8, alpha = 0.9) +
xlab(paste0("PC1: ",percentVar[1],"% variance")) +
ylab(paste0("PC2: ",percentVar[2],"% variance")) +
geom_hline(yintercept = 0, linetype = "dotted", alpha = 0.5) +
geom_vline(xintercept = 0, linetype = "dotted", alpha = 0.5) +
geom_text_repel(aes(label = rownames(pca)), size = 3.5) +
coord_fixed() +
scale_color_manual(values = c("darkgoldenrod1", "chocolate1", "brown"), name = "Age", labels = c("20 days", "30 days", "40 days")) +
ggtitle("PCA RNAseq samples") +
scale_shape_discrete(name = "Age", labels = c("20 days", "30 days", "40 days")) +
theme_light() +
theme(legend.position = "top", legend.direction = "horizontal", plot.title = element_text(hjust = 0.5))
pca_plot
#use the same dds object generated before for the PCA, and perform the second step
dds2 = DESeq(dds1)
#compute the results object and set the alpha for the FDR at the threshold that I want to choose after
res_s = results(dds2, contrast = c("days", "40", "20"), alpha = 0.05)
sign_s = res_s %>% as.data.frame() %>% filter(padj <= 0.05)
#visualization through Volcano plot
#shirk the log2fold change for visualization
lfc_apeglm =lfcShrink(dds2, res = res_s, coef = "days_40_vs_20" , type="apeglm")
#add information that needs to be displayed in the plot
apeglm_for_plot = lfc_apeglm %>% as.data.frame() %>%
rownames_to_column(var = "flybase") %>% dplyr::select(c("flybase", "log2FoldChange", "padj")) %>% na.omit() %>%
mutate(significance = ifelse(padj <= 0.05, "signif", "non_signif")) %>%
mutate(symbol = mapIds(org.Dm.eg.db,
keys= .$flybase,
column="SYMBOL",
keytype="ENSEMBL",
multiVals="first")) %>%
mutate(annot = ifelse(log2FoldChange < -2, symbol, ifelse(log2FoldChange > 2, symbol, ""))) %>%
mutate(annot = ifelse(is.na(annot), flybase, annot))
#plot, label for the genes that have a log2FC > |2|
ggplot(apeglm_for_plot, aes(log2FoldChange, -log10(padj)))+ geom_point(aes(col = significance), alpha = 0.5) + theme_light() +
scale_color_manual(name = "FDR 5%", labels = c("Non significant", "Significant"), values = c("lightgrey", "red")) +
theme(legend.position = "bottom", legend.direction = "horizontal") + geom_text_repel(aes(label = annot), size = 4.3) +
ylab("-log10(FDR)") + xlab("log2FoldChange Smurfs/non-Smurfs")
##use the same dataset used for the PCA, vst (stabilized variance) rather than simply the normalized counts
#filter for the DEGs
vst_df = vst %>% assay %>% as.data.frame()
vst_diff = vst_df[rownames(vst_df) %in% rownames(sign_s),]
require(heatmap3)
##prepare annotation for the heatmap plot
vst_mat_005 = vst_diff %>% as.matrix
annot = data.frame(samples = colnames(vst_mat_005)) %>%
mutate(condition = ifelse(grepl("n", .$samples), "NS", "S")) %>%
mutate(age = ifelse(grepl("20", .$samples), "20",
ifelse(grepl("40", .$samples), "40",
ifelse(grepl("30", .$samples), "30", "32")))) %>%
#mutate(smurfness = ifelse(condition == "NS", "lightgrey", "blue")) %>%
mutate(days = ifelse(age == "20", "darkgoldenrod1", ifelse(age == "40", "brown", "chocolate1")))
annot_hp = annot %>% select(c("days")) %>% as.matrix
rownames(annot_hp) = annot$samples
#plot with heatmap3, default for computing the matrix is correlation
heatmap3(vst_mat_005 , scale = "row", ColSideColors = annot_hp,
labRow   = FALSE, labCol = FALSE, showRowDendro = F, legendfun = function()
showLegend(legend = c("20 days", "30 days", "40 days"),
fill = c("darkgoldenrod1", "chocolate1", "brown"), lwd = 0,
col=colorRampPalette(c("green","black","red"))(1024)))
require(clusterProfiler)
##list of genes to use: as reccomended in the DESeq2 guidelines, use of the shrinked log2FC for ranking
lfc_apeglm = lfc_apeglm %>% as.data.frame() %>% rownames_to_column(var = "gene_flybase") %>%
mutate(entrez = mapIds(org.Dm.eg.db,
keys = .$gene_flybase,
column = "ENTREZID", #add the entrez nomenclature that is required (as the downloaded GO are annotated this way)
keytype = "ENSEMBL",
multiVals = "first"))
#filter only the genes we are interested in
res_apeg <- lfc_apeglm  %>% filter(padj <= 0.05) %>%  dplyr::select(c("gene_flybase", "log2FoldChange", "entrez"))
#creating the gene list and ranking it
#getting the sorted gene list
gene_list <- as.numeric(res_apeg$log2FoldChange)
names(gene_list) <- as.character(res_apeg$gene_flybase)
gene_list = gene_list[!is.na(names(gene_list))] %>% .[!duplicated(names(.))] %>% sort(., decreasing = TRUE)
#run the analysis
n = 1 #number of times repeating
P = 80 #percentage for selection
pval = 0.05 #threshold to apply
gse_go = vector("list", n)
organism = "org.Dm.eg.db"
library(organism, character.only = TRUE) #library is already loaded
set.seed(123)
for (i in 1:length(gse_go)) {
gse_go[[i]] <- gseGO(geneList= gene_list,
ont ="BP",
keyType = "ENSEMBL",
nPerm = 15000,
minGSSize = 10,
maxGSSize = 600,
pvalueCutoff = 0.05, #change the significance level
verbose = TRUE,
OrgDb = organism,
pAdjustMethod = "fdr") # %>% as.data.frame()
}
#perform the filtering with the 80% threshold
#transform the objects in the list to dataframe
df_gse = lapply(gse_go, function(x) as.data.frame(x))
#extract the categories of interest
categories = lapply(df_gse, function(x) x$Description)
#IF I WANT TO KEEP ONLY THE ONES THAT ARE OCCURING EVERYTIME
#Reduce(intersect, a )
#IF I WANT TO FILTER FOR P% PRESENCE OF THE CATEGORY
filtering_vector = tibble(category = unlist(categories)) %>% #unlist the list and making it a tibble
group_by(category) %>%
summarise(count = n()) %>% #group by category and generate a new column counting how many times a category occurs
mutate(percentage_presence = count/n*100) %>% #adding a column with the persentage
#arrange(desc(count)) %>% #adding this only if we want to visualize
filter(percentage_presence >= P)
filtering_vector
sign_s %>% dim
#run the analysis
n = 50 #number of times repeating
P = 80 #percentage for selection
pval = 0.05 #threshold to apply
gse_go = vector("list", n)
organism = "org.Dm.eg.db"
library(organism, character.only = TRUE) #library is already loaded
set.seed(123)
for (i in 1:length(gse_go)) {
gse_go[[i]] <- gseGO(geneList= gene_list,
ont ="BP",
keyType = "ENSEMBL",
nPerm = 15000,
minGSSize = 10,
maxGSSize = 600,
pvalueCutoff = 0.05, #change the significance level
verbose = TRUE,
OrgDb = organism,
pAdjustMethod = "fdr") # %>% as.data.frame()
}
warnings()
#perform the filtering with the 80% threshold
#transform the objects in the list to dataframe
df_gse = lapply(gse_go, function(x) as.data.frame(x))
#extract the categories of interest
categories = lapply(df_gse, function(x) x$Description)
#IF I WANT TO KEEP ONLY THE ONES THAT ARE OCCURING EVERYTIME
#Reduce(intersect, a )
#IF I WANT TO FILTER FOR P% PRESENCE OF THE CATEGORY
filtering_vector = tibble(category = unlist(categories)) %>% #unlist the list and making it a tibble
group_by(category) %>%
summarise(count = n()) %>% #group by category and generate a new column counting how many times a category occurs
mutate(percentage_presence = count/n*100) %>% #adding a column with the persentage
#arrange(desc(count)) %>% #adding this only if we want to visualize
filter(percentage_presence >= P)
filtering_vector %>% dim
filtering_vector
##find a gse_go that has all of them
df_gse[[1]]$Description %in% filtering_vector$category %>% sum
##FOR THE PLOT
plot_gse = gse_go[[1]]
emapplot(plot_gse, showCategory = filtering_vector$category, color = "NES",
layout = "fr", cex_label_category = 0.1) + scale_color_gradient(low = "blue" , high = "red" ) #selecting the categories we want with "showCategory"
save(gse_go, "gse_go_smurfs_analysis.RData")
dev.off()
save(gse_go, file = "gse_go_smurfs_analysis.RData")
sign_s %>% dim
sign_s %>% filter(log2FoldChange > 0)
sign_s %>% filter(log2FoldChange > 0) %>% dim
plot_gse %>% head
plot_gse %>% class
##find a gse_go that has all of them
df_gse[[1]]$Description %in% filtering_vector$category %>% sum
filtering_vector %>% dim
df_to_plot = df_gse[[1]]$Description %in% filtering_vector$category
df_to_plot
df_to_plot = df_gse[[1]][df_gse[[1]]$Description %in% filtering_vector$category,]
df_to_plot
df_to_plot %>% dim
df_to_plot$NES > 0 %>% sum
df_to_plot$NES < 0 %>% sum
(df_to_plot$NES) < 0 %>% sum
(df_to_plot$NES < 0) %>% sum
(df_to_plot$NES > 0) %>% sum
require(ggplot2)
pca <- prcomp(iris[,-5])
dataset = data.frame(species = iris[,"Species"], pca = pca$x)
mx <- mean(dataset$pca.PC1)
my <- mean(dataset$pca.PC2)
ggplot(dataset) +
geom_point(aes(pca.PC1, pca.PC2, colour = species, shape = species),
size = 4) +
geom_point(aes(mx,my), size = 7)
library(ggbiplot)
data(wine)
wine.pca <- prcomp(wine, center = TRUE, scale. = TRUE)
df.wine.x <- as.data.frame(wine.pca$x)
df.wine.x$groups <- wine.class
pca.centroids <- aggregate(df.wine.x[,1:13], list(Type = df.wine.x$groups), mean)
pca.centroids
dist(rbind(pca.centroids[pca.centroids$Type == "barolo",2:3],pca.centroids[pca.centroids$Type == "grignolino",2:3]), method = "euclidean")
rm(list = ls())
#sourcing a few functions to get the coldata attributes in deseq2
source("/home/f-zane/Google Drive/RNAseq_Analysis/ENSEMBL_annotation/Deseq/coldata_functions.R")
##data uploading
raw_data <- fread("/home/f-zane/Google Drive/RNAseq_Analysis/ENSEMBL_annotation/Deseq/Galaxy170-[FeatureCounts_Table_-_Short_Headers].tabular") %>%
column_to_rownames(var="Geneid")
library(data.table)
library(tidyverse)
library(DESeq2)
library(edgeR)
library(ggfortify)
#sourcing a few functions to get the coldata attributes in deseq2
source("/home/f-zane/Google Drive/RNAseq_Analysis/ENSEMBL_annotation/Deseq/coldata_functions.R")
##data uploading
raw_data <- fread("/home/f-zane/Google Drive/RNAseq_Analysis/ENSEMBL_annotation/Deseq/Galaxy170-[FeatureCounts_Table_-_Short_Headers].tabular") %>%
column_to_rownames(var="Geneid")
#removing genes with 0 counts (most of all are )
raw_data = raw_data[which(rowSums(raw_data) > 0),] #to avoid
##deriving the coldata attributes (which sample is S, 20days etc..)
days <-  sapply(colnames(raw_data), getting_days)
time <-  sapply(colnames(raw_data), getting_time)
condition <-  sapply(colnames(raw_data), getting_condition)
#creating the colData object
colData <- data.frame(samples = colnames(raw_data), condition = condition, time = time, days = days, row.names = NULL)
colData$days = as.factor(colData$days)
#creating the dds object
dds <- DESeqDataSetFromMatrix(countData = raw_data, colData = colData, design = ~ condition)
##with VST transformation (variance stabilizing trasformation)
##getting variance independent from the mean and get homoscedasticity
##STANDARDIZATION PROCESS REQUIRED FOR THE PCA
vst <- vst(dds)
pca_1000 = plotPCA(vst, intgroup = c("condition", "days"), ntop =1000, returnData = TRUE)
#pca_2000 = plotPCA(vst, intgroup = c("condition", "days"), ntop =2000, returnData = TRUE)
#pca_all = plotPCA(vst, intgroup = c("condition", "days"), ntop = nrow(raw_data), returnData = TRUE)
percentVar <- round(100 * attr(pca_1000, "percentVar"))
#percentVar <- round(100 * attr(pca_all, "percentVar"))
##same with rlog transformation
# The idea is to shrink sample-to-sample differences when
# there is little information (low counts) and to preserve
# these differences when there is information (high counts). (M.Love)
rlog <- rlog(dds)
pca_1000_log = plotPCA(rlog, intgroup = c("condition", "days"), ntop =1000, returnData = TRUE)
#pca_7000_log = plotPCA(rlog, intgroup = c("condition", "days"), ntop =2000, returnData = TRUE)
#pca_all_log = plotPCA(rlog, intgroup = c("condition", "days"), ntop = nrow(raw_data), returnData = TRUE)
percentVar_log <- round(100 * attr(pca_1000_log, "percentVar"))
#percentVar <- round(100 * attr(pca_all_log, "percentVar"))
#plot the pca without
#color=condition plot
p = ggplot(pca_1000, aes(PC1, PC2, color=condition, shape=days)) +
geom_point(size=2) +
xlab(paste0("PC1: ",percentVar[1],"% variance")) +
ylab(paste0("PC2: ",percentVar[2],"% variance")) +
coord_fixed() +
ggtitle("PCA RNAseq samples vst transform ntop = 1000 ")
p_log = ggplot(pca_1000_log, aes(PC1, PC2, color=condition, shape=days)) +
geom_point(size=2) +
xlab(paste0("PC1: ",percentVar_log[1],"% variance")) +
ylab(paste0("PC2: ",percentVar_log[2],"% variance")) +
coord_fixed() +
ggtitle("PCA RNAseq samples rlog transform ntop = 1000")
p + theme(
plot.title = element_text(color="black", size=12, face="bold", hjust = 0.5, family = ""))
#ggsave("pcavst.pdf")
p_log + theme(
plot.title = element_text(color="black", size=12, face="bold", hjust = 0.5, family = ""))
#ggsave("pcarlog.pdf")
## For the presentation
# p +
#   ggtitle("PCA RNAseq samples VST") +
#   scale_color_discrete(name = "Condition", labels = c("Non Smurf", "Smurf")) +
#   scale_shape_discrete(name = "Number of days") +
#   theme(
#     plot.title = element_text(color="black", size=12, face="bold", hjust = 0.5, family = ""),
#     plot.margin=grid::unit(c(0,0,0,0), "mm"))
#from the raw data computing the scaling factor
tmm_factor = calcNormFactors(raw_data, method = "TMM") #this function gives back the scaling factor
#now to get the TMM
#count / (library size * normalization factor)
#library size == total number of reads for the given sample
#library size*normalization factor = effective library size
#get (library size * normalization factor)
library_size <- as.vector(colSums(raw_data))
multiply = function(x,y) {x*y}
effective_library_size = mapply(multiply, tmm_factor, library_size)
# tmm
tmm_data = matrix(NA, nrow = nrow(raw_data), ncol = length(effective_library_size)) %>%
as.data.frame()
for (i in 1:ncol(raw_data)){
tmm_data[,i] = raw_data[,i]/effective_library_size[i]
}
colnames(tmm_data) = colnames(raw_data)
rownames(tmm_data) = rownames(raw_data)
##then get CPM
cpm_data = cpm(raw_data, log= T)
transpose_cpm = t(as.matrix(cpm_data)) %>%
as.data.table()
##select the top genes
rv <- rowVars(cpm_data)
# select the ntop genes by variance
ntop= 1000
select <- order(rv, decreasing=TRUE)[seq_len(ntop)]
# perform a PCA on the data in assay(x) for the selected genes
pca <- prcomp(t(cpm_data[select,]))
##plot the pca*
days <-  sapply(colnames(raw_data), getting_days)
time <-  sapply(colnames(raw_data), getting_time)
condition <-  sapply(colnames(raw_data), getting_condition)
transpose_cpm_annot = mutate(transpose_cpm, condition = condition, days = days)
rownames(transpose_cpm_annot) = colnames(raw_data)
# pca = prcomp(transpose_cpm)
p = autoplot(pca,  data = transpose_cpm_annot, colour = "condition", label = TRUE,
label.size =3, main = "PCA log2cpm ntop = 1000")
p + theme(
plot.title = element_text(color="black", size=12, face="bold", hjust = 0.5, family = ""))
data_tsne = t(cpm_data) %>%
#normalize_input() %>%  #already normalized
as.data.frame() %>%
mutate(condition = condition, days = days)
rownames(data_tsne) <- colnames(cpm_data)
set.seed(42)
require(FactoMineR)
#getting the PCA extracting different numbers of components
res.pca_2<- PCA(t(cpm_data[select,]), ncp = 2)
res.pca_10<- PCA(t(cpm_data[select,]), ncp = 10)
res.pca_30<- PCA(t(cpm_data[select,]), ncp = 30)
res.pca_30
?PCA
res.hcpc_2 = HCPC(res.pca_2, order = TRUE)
library(tidyverse)
library(tidyverse)
install.packages(tidyverse)
install.packages("tidyverse")
installed.packages()
#print the R environment
Rversion()
#print the R environment
R.version()
#print the R environment
R.Version()
#print the R environment
R_version =R.Version()
#print the R environment
R_version = R.Version()
#set the working directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(tidyverse)
#upload the data, prepare the normalized counts for downstream analysis: use the DESeq2 workflow for consistency
##upload raw data
require(data.table);library(DESeq2)
raw_data <- fread("../data/RNAseq_raw_data_matrix.tabular") %>%
column_to_rownames(var="Geneid")
##with outliers but removing genes with 0 counts
raw_data = raw_data[which(rowSums(raw_data) > 0),]
#creation of the colData object with data annotation, needed for the DESeq2 framework
colData = data.frame(samples = colnames(raw_data)) %>%
mutate(days = ifelse(str_starts(samples, "20"), 20, ifelse(str_starts(samples, "40"), 40, 30))) %>% #chronological age
mutate(condition = ifelse(str_detect(samples, "s"), "S", "NS")) %>% #condition (smurfs or non-smurfs)
mutate(time = ifelse(str_detect(samples, "M"), "mixed", ifelse(str_detect(samples, "1d"), "24h", "5h"))) %>% #moment of sampling after the smurf transition
column_to_rownames(var="samples") #respect the format required by Deseq2 by putting samples as rownames
#Create dds object, which will also be used in further analysis (differential gene expression)
#design the matrix to keep into consideration the different biological variables
dds1 <- DESeqDataSetFromMatrix(countData = raw_data, colData = colData, design = ~ condition + days)
#obtain the normamlized counts from the object
dds_norm <- estimateSizeFactors(dds1)
norm_data = DESeq2::counts(dds_norm, normalized = TRUE) %>% as.data.frame() %>% mutate(mean = rowMeans(.)) %>% filter(mean > quantile(mean, 0.25)) %>% select(-mean)
##separate the data in different datasets (age and conditon)
day_20 = norm_data %>%  dplyr::select(contains("20"))
day_30 = norm_data %>%  dplyr::select(matches("30|32"))
day_40 = norm_data %>%  dplyr::select(contains("40"))
#day 20, smurfs and non-smurfs
day_20_s = day_20 %>% dplyr::select(contains("s"))
day_20_ns = day_20 %>% dplyr::select(contains("n"))
#day 30, smurfs and non-smurfs
day_30_s = day_30 %>% dplyr::select(contains("s"))
day_30_ns = day_30 %>% dplyr::select(contains("n"))
#day 40, smurfs and non-smurfs
day_40_s =  day_40 %>% dplyr::select(contains("s"))
day_40_ns = day_40 %>% dplyr::select(contains("n"))
###compute the sd and then divide by the mean (relative standard deviation)
require(genefilter)
#day 20 sd, smurf and non-smurf
day_20_s_sd = day_20_s %>% mutate(var20s = rowSds(.)) %>% mutate(mean = rowMeans(day_20_s)) %>% mutate(var20s2 = var20s/mean)
day_20_ns_sd = day_20_ns %>% mutate(var20ns = rowSds(.)) %>% mutate(mean = rowMeans(day_20_ns)) %>% mutate(var20ns2 = var20ns/mean)
#day 30 sd, smurf and non-smurf
day_30_s_sd = day_30_s %>% mutate(var30s = rowSds(.)) %>% mutate(mean = rowMeans(day_30_s)) %>% mutate(var30s2 = var30s/mean)
day_30_ns_sd = day_30_ns %>% mutate(var30ns = rowSds(.)) %>% mutate(mean = rowMeans(day_30_ns))  %>% mutate(var30ns2 = var30ns/mean)
#day 40 sd, smurf and non-smurf
day_40_s_sd =  day_40_s %>% mutate(var40s = rowSds(.)) %>% mutate(mean = rowMeans(day_40_s)) %>% mutate(var40s2 = var40s/mean)
day_40_ns_sd = day_40_ns %>% mutate(var40ns = rowSds(.)) %>% mutate(mean = rowMeans(day_40_ns)) %>% mutate(var40ns2 = var40ns/mean)
###smurf
gene_info20_s = data.frame(gene = rownames(day_20_s_sd), sd = day_20_s_sd$var20s2)
gene_info30_s = data.frame(gene = rownames(day_30_s_sd), sd = day_30_s_sd$var30s2)
gene_info40_s = data.frame(gene = rownames(day_40_s_sd), sd = day_40_s_sd$var40s2)
###select the last 25%
gene_info20_s %>% dplyr::select(sd) %>% unlist %>% quantile(na.rm = TRUE) #75% 0.247651793 and max 2.000000000
day_20_s_sd
day_20_s_sd %>% head
###smurf
gene_info20_s = data.frame(gene = rownames(day_20_s_sd), sd = day_20_s_sd$var20s2)
gene_info20_s
gene_info20_s %>% head
day_20_s_sd %>% hed
day_20_s_sd %>% head
day_20_s_sd %>% head(n=2)
day_40_s_sd %>% head(n=2)
day_20_ns_sd %>% head
day_20_ns_sd %>% select(-c("mean", "var20ns2"))
day_20_ns_sd %>% select(-c("mean", "var20ns2")) %>% head
day_20_ns_sd %>% select(-c("mean", "var20ns", "var20ns2")) %>% head
day_20_ns_sd %>% select(-c("mean", "var20ns", "var20ns2"))
day_30_ns_sd %>% select(-c("mean", "var30ns", "var30ns2"))
day_40_ns_sd %>% select(-c("mean", "var40ns", "var40ns2"))
day_40_ns_sd %>% select(-c("mean", "var40ns", "var40ns2")) %>% head
n20 = day_20_ns_sd %>% select(-c("mean", "var20ns", "var20ns2"))
n30 = day_30_ns_sd %>% select(-c("mean", "var30ns", "var30ns2"))
n40 = day_40_ns_sd %>% select(-c("mean", "var40ns", "var40ns2"))
n20 %>% dim
cbind(n20, n30, n40)
View(n20)
n20 %>% head
n30 %>% head
n40 %>% head
all_n = cbind(n20, n30, n40)
?gather
n20 = day_20_ns_sd %>% select("var20ns2"))
n20 = day_20_ns_sd %>% select("var20ns2")
n20
n20 %>% head
n30
n40 = day_40_ns_sd %>% select("var40ns2")
n20 = day_20_ns_sd %>% select("var20ns2")
n30 = day_30_ns_sd %>% select("var30ns2")
n40 = day_40_ns_sd %>% select("var40ns2")
n20
all_n = cbind(n20, n30, n40)
all_n
all_n %>% head
all_n = cbind(n20, n30, n40) %>% select( var20ns2 > var40ns2 & var30ns2 > var40ns2)
all_n = cbind(n20, n30, n40) %>% filter(var20ns2 > var40ns2 & var30ns2 > var40ns2)
all_n
all_n %>% dim
all_n = cbind(n20, n30, n40) %>% filter(var20ns2 > var30ns2 & var30ns2 > var40ns2)
all_n %>% dim
all_n
cbind(n20, n30, n40) %>% filter(var20ns2 < var30ns2 & var30ns2 < var40ns2)
cbind(n20, n30, n40) %>% filter(var20ns2 < var30ns2 & var30ns2 < var40ns2) %>% dim
all_n = cbind(n20, n30, n40) %>% filter(var20ns2 > var30ns2 & var30ns2 > var40ns2) ##1800
all_n %>% dim
all_n %>% rownames()
?write.table
write.table(all_n %>% rownames(), "../../noise_decreasing_only.txt", quote = FALSE, sep = "\t", row.names = FALSE, col.names = FALSE)
getwd()
write.table(all_n %>% rownames(), "../noise_decreasing_only.txt", quote = FALSE, sep = "\t", row.names = FALSE, col.names = FALSE)
write.table(day_20_ns_sd %>% rownames(), "../../noise_decreasing_only_background.txt", quote = FALSE, sep = "\t", row.names = FALSE, col.names = FALSE)
FBgn0028707
all_n %>% filter("FBgn0028707" %in% rowanames(.))
all_n %>% filter("FBgn0028707" %in% row.names(.))
all_n %>% filter(rownames(.) == 'FBgn0028707')
all_n %>% filter(rownames(.) == 'FBgn0263755')
all_n %>% filter(rownames(.) == 'FBgn0263755')
day_20_ns_sd %>% filter(rownames(.) == 'FBgn0263755')
all_n %>% rownames()
(all_n %>% rownames()) %in% "FBgn0263111"
all_n %>% dim
all_n %>% filter(rownames(.) = "FBgn0263111")
all_n %>% filter(rownames(.) == "FBgn0263111")
all_n %>% filter(rownames(.) == "FBgn0263755")
(all_n %>% rownames()) %in% "FBgn0263755"
(all_n %>% rownames()) %in% "FBgn0263755"  %>% sum
all_n = cbind(n20, n30, n40) %>% filter(var20ns2 > var30ns2 & var30ns2 > var40ns2) %>%mutate(symbol = mapIds(org.Dm.eg.db, keys= rownames(.),
)
)
library(org.Dm.eg.db)
all_n = cbind(n20, n30, n40) %>% filter(var20ns2 > var30ns2 & var30ns2 > var40ns2) %>%mutate(symbol = mapIds(org.Dm.eg.db, keys= rownames(.),
column="SYMBOL",
keytype="ENSEMBL",
multiVals="first"))##841 with only decreasing
all_n
all_n[grep("Su", .$symbol, ignore.case =TRUE),]
all_n[grep("Su", all_n$symbol, ignore.case =TRUE),]
n20 %>% filter(rownames(.) == 'FBgn0263755')
n30 %>% filter(rownames(.) == 'FBgn0263755')
write.table(all_n %>% rownames(), "../../noise_decreasing_only.txt", quote = FALSE, sep = "\t", row.names = FALSE, col.names = FALSE)
write.table(day_20_ns_sd %>% rownames(), "../../noise_decreasing_only_background.txt", quote = FALSE, sep = "\t", row.names = FALSE, col.names = FALSE)
all_n[grep("Su", all_n$symbol, ignore.case =TRUE),]
n40 %>% dim
